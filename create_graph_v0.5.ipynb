{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from igraph import *\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "import databricks.koalas as ks\n",
    "from scipy.spatial.distance import euclidean\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = \"./train_features/\"\n",
    "test_features = \"./test_features/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicGraph(Graph):\n",
    "    \n",
    "    def __init__(self, *args, **kwds):\n",
    "        super(BasicGraph, self).__init__(*args, **kwds)\n",
    "        \n",
    "    def concat(self, graph2):\n",
    "        vs_attributes = self.vs.attributes()\n",
    "        es_attributes = self.es.attributes()\n",
    "\n",
    "        vs_attrs = {}\n",
    "        es_attrs = {}\n",
    "        \n",
    "        for attribute in vs_attributes:\n",
    "            vs_attrs[attribute] = self.vs[attribute] + graph2.vs[attribute]\n",
    "        \n",
    "        for attribute in es_attributes:\n",
    "            es_attrs[attribute] = self.es[attribute] + graph2.es[attribute]\n",
    "        \n",
    "        aux = self + graph2\n",
    "        \n",
    "        aux.set_vs_attributes(vs_attrs)\n",
    "        aux.set_es_attributes(es_attrs)\n",
    "        \n",
    "        return aux\n",
    "        \n",
    "    def set_vs_attributes(self, attr):\n",
    "        for key, value in attr.items():\n",
    "            self.vs[key] = value\n",
    "    \n",
    "    def set_es_attributes(self, attr):\n",
    "        for key, value in attr.items():\n",
    "            self.es[key] = value\n",
    "    \n",
    "    def mst(self, weights = None):\n",
    "        if weights is not None:\n",
    "            return self.spanning_tree(weights=self.es[\"weight\"])\n",
    "        return self.spanning_tree(weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadDataframe():\n",
    "    \n",
    "    def __init__(self, features_file = \"./train_features/\"):\n",
    "        self.features_file = features_file\n",
    "    \n",
    "    def _sortKeyFunc(self, s):\n",
    "        out = int(re.findall(\"[0-9]+\", s)[0])\n",
    "        return out\n",
    "    \n",
    "    def _print_while_reads(self, indice, total):\n",
    "        sys.stdout.write(\"Dataframes lidos: %f %%  \\r\" % ((indice/total)*100) )\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    def _get_batch_dfs(self):\n",
    "        files = sorted(glob.glob(self.features_file+\"*\"), key=self._sortKeyFunc)\n",
    "        for file in files:\n",
    "            yield pd.read_pickle(file)\n",
    "        \n",
    "    def classes_counts(self):\n",
    "        unique_counts = defaultdict(int)\n",
    "        for df in self._get_batch_dfs():\n",
    "            keys, values = np.unique(df.global_class, return_counts = True)\n",
    "            for key, value in zip(keys, values):\n",
    "                unique_counts[key] += value\n",
    "        \n",
    "        return dict(unique_counts)\n",
    "    \n",
    "    def bboxes_counts(self):\n",
    "        lengths = np.empty((0)).astype(int)\n",
    "        for df in self._get_batch_dfs():\n",
    "            lengths = np.append(lengths, df.applymap(self._count_features).sum(axis=1).to_numpy().astype(int))\n",
    "        \n",
    "        return lengths\n",
    "    \n",
    "    def global_classes(self):\n",
    "        global_classes = np.empty((0))\n",
    "        for df in self._get_batch_dfs():\n",
    "            global_classes = np.append(global_classes, df.global_class.to_numpy())\n",
    "        \n",
    "        return global_classes\n",
    "    \n",
    "    def get_global_names(self):\n",
    "        self.classes = self.classes_counts()\n",
    "        classes_list = []\n",
    "        for key, value in self.classes.items():\n",
    "            for i in range(value):\n",
    "                classes_list.append(key + \"_\" + str(i))\n",
    "        \n",
    "        return classes_list\n",
    "    \n",
    "    def _count_features(self, data):\n",
    "        if isinstance(data, np.ndarray):\n",
    "            return 1\n",
    "        return 0\n",
    "    \n",
    "    def get_bbox_names(self):\n",
    "        classes_list = []\n",
    "        \n",
    "        lengths = self.bboxes_counts()\n",
    "        global_classes = self.global_classes()\n",
    "        \n",
    "        relative_ids = np.empty((0)).astype(int)\n",
    "        for count in self.classes.values():\n",
    "            relative_ids =  np.append(relative_ids, np.arange(count).astype(int))\n",
    "        \n",
    "        for global_class, length, relative_id in zip(global_classes, lengths, relative_ids):\n",
    "            for i in range(length):\n",
    "                classes_list.append(global_class + \"_\" + str(relative_id) + \"_\" + str(i))\n",
    "                \n",
    "        return classes_list\n",
    "                \n",
    "    def get_names(self):\n",
    "        names = []\n",
    "        names.extend(self.get_global_names())\n",
    "        names.extend(self.get_bbox_names())\n",
    "        \n",
    "        return np.asarray(names)\n",
    "    \n",
    "    \n",
    "    def _return_only_features(self, data):\n",
    "        if isinstance(data, np.ndarray):\n",
    "            return data\n",
    "        return None\n",
    "\n",
    "    def get_global_features(self):\n",
    "        features = []\n",
    "        for df in self._get_batch_dfs():\n",
    "            for feature in df.global_feature.to_numpy():\n",
    "                features.extend(feature)\n",
    "            \n",
    "        return features\n",
    "        \n",
    "    def get_bbox_features(self):\n",
    "        features = []\n",
    "        for df in self._get_batch_dfs():\n",
    "            ff = df.applymap(self._return_only_features).to_numpy()\n",
    "            for f in ff:\n",
    "                for feature in f:\n",
    "                    if feature is not None:\n",
    "                        features.extend(feature)\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def get_features(self):\n",
    "        features = []\n",
    "        features.extend(self.get_global_features())\n",
    "        features.extend(self.get_bbox_features())\n",
    "\n",
    "        return np.asarray(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateGraph(ReadDataframe, BasicGraph):\n",
    "    \n",
    "    def __init__(self, features_file = \"./train_features/\"):\n",
    "        self.features_file = features_file\n",
    "        ReadDataframe.__init__(self, features_file)\n",
    "        BasicGraph.__init__(self)\n",
    "        \n",
    "    def build(self):\n",
    "        g = BasicGraph.Full(0)\n",
    "        self.classes = self.classes_counts()\n",
    "        for classe_count in self.classes.values():\n",
    "            g = g + BasicGraph.Full(classe_count)\n",
    "        \n",
    "        self.lengths = self.bboxes_counts()\n",
    "        for length in self.lengths:\n",
    "            g = g + BasicGraph.Full(length)\n",
    "        \n",
    "        g.vs[\"name\"] = self.get_names()\n",
    "        g.vs[\"feature\"] = self.get_features()\n",
    "        \n",
    "        self.g = g\n",
    "        \n",
    "    def auto_connect(self):\n",
    "        names = self.get_global_names()\n",
    "    \n",
    "        for name, length in zip(names, self.lengths):\n",
    "            global_indice = self.g.vs.find(name=name).index\n",
    "            \n",
    "            bbox_indice = self.g.vs.find(name=name + \"_0\").index\n",
    "            self.g.add_edges([(global_indice, actual_indice) for actual_indice in range(bbox_indice, bbox_indice+length)])\n",
    "        \n",
    "    def mst(self, weights = None):\n",
    "        return self.g.mst(weights)\n",
    "    \n",
    "    def set_weights(self):\n",
    "        for indice, pair in enumerate(self.g.get_edgelist()):\n",
    "            features = self.g.vs[pair][\"feature\"]\n",
    "            self.g.es[indice][\"weight\"] = euclidean(features[0].reshape(-1), features[1].reshape(-1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graph = CreateGraph()\n",
    "train_graph.build()\n",
    "train_graph.auto_connect()\n",
    "train_graph.set_weights()\n",
    "train_graph = train_graph.mst()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IGRAPH UNW- 45275 45222 -- \\n+ attr: feature (v), name (v), weight (e)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_graph.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph = CreateGraph(test_features)\n",
    "test_graph.build()\n",
    "test_graph.auto_connect()\n",
    "test_graph.set_weights()\n",
    "test_graph = test_graph.mst()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IGRAPH UNW- 10807 10754 -- \\n+ attr: feature (v), name (v), weight (e)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_graph.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = train_graph.concat(test_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IGRAPH UNW- 56082 55976 -- \\n+ attr: feature (v), name (v), weight (e)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"graph.pkl\", \"wb\") as f:\n",
    "    graph.write_pickle(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
